2.166

2.1440346719252963

    model = LGBMRegressor(objective='quantile', # quantile regression 으로서 0.1 ~ 0.9 의 값을 체크한다.
                          boosting ='dart',
                          alpha=q, # alpha 에 q 를 넣게되면 추정을 quantile 로 해준다.
                          drop_rate = 0.2,
                          n_estimators= 300,
                          learning_rate= 0.3,
                          min_data_in_leaf = 1000,
                          bagging_fraction = 0.8,
                          max_depth = 5,
                          seed = 42)


[1.4332202959477305,
 2.357502237412376,
 2.86924522877102,
 3.0495775022826277,
 2.925345091612535,
 2.588445826496567,
 2.109061285976831,
 1.495908521258979,
 0.8023008705710583]

[1.4706724918542116,
 2.3519718151099966,
 2.8463198780897927,
 2.9893181547233048,
 2.79981627715749,
 2.416700560102744,
 1.932439432902106,
 1.3796079212182446,
 0.7751707031677093]